{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzH58Wqrkhle"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 1. Create a random tensor of shape (4, 6)\n",
        "tensor_4_6 = tf.random.uniform(shape=(4, 6))\n",
        "print(\"Original tensor:\")\n",
        "print(tensor_4_6)\n",
        "\n",
        "# 2. Find its rank and shape\n",
        "rank = tf.rank(tensor_4_6)\n",
        "shape = tf.shape(tensor_4_6)\n",
        "print(f\"\\nRank: {rank}\")\n",
        "print(f\"Shape: {shape}\")\n",
        "\n",
        "# 3. Reshape and transpose\n",
        "# Reshape to (2, 3, 4)\n",
        "reshaped_tensor = tf.reshape(tensor_4_6, (2, 3, 4))\n",
        "print(\"\\nReshaped tensor (2, 3, 4):\")\n",
        "print(reshaped_tensor)\n",
        "\n",
        "# Transpose to (3, 2, 4)\n",
        "transposed_tensor = tf.transpose(reshaped_tensor, perm=[1, 0, 2])\n",
        "print(\"\\nTransposed tensor (3, 2, 4):\")\n",
        "print(transposed_tensor)\n",
        "\n",
        "# Print rank and shape after reshaping/transposing\n",
        "print(f\"\\nRank after reshaping: {tf.rank(reshaped_tensor)}\")\n",
        "print(f\"Shape after reshaping: {tf.shape(reshaped_tensor)}\")\n",
        "print(f\"Rank after transposing: {tf.rank(transposed_tensor)}\")\n",
        "print(f\"Shape after transposing: {tf.shape(transposed_tensor)}\")\n",
        "\n",
        "# 4. Broadcasting and addition\n",
        "# Create a smaller tensor of shape (1, 4)\n",
        "smaller_tensor = tf.random.uniform(shape=(1, 4))\n",
        "print(\"\\nSmaller tensor (1, 4):\")\n",
        "print(smaller_tensor)\n",
        "\n",
        "# Broadcasting and adding\n",
        "broadcasted_sum = reshaped_tensor + smaller_tensor[:, tf.newaxis, :]\n",
        "print(\"\\nResult after broadcasting and addition:\")\n",
        "print(broadcasted_sum)\n",
        "\n",
        "# 5. Explanation of broadcasting in TensorFlow\n",
        "print(\"\\nExplanation of broadcasting:\")\n",
        "print(\"Broadcasting in TensorFlow allows arithmetic operations between tensors of different shapes.\")\n",
        "print(\"The smaller tensor (1, 4) is broadcast to match the shape of the reshaped tensor (2, 3, 4).\")\n",
        "print(\"1. The smaller tensor is expanded to (1, 1, 4).\")\n",
        "print(\"2. This is then repeated to match the shape (2, 3, 4).\")\n",
        "print(\"3. Finally, element-wise addition is performed.\")\n",
        "print(\"This allows efficient operations between tensors of different shapes without manually replicating data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCCjhO82hJvv",
        "outputId": "b48f1e00-938d-4a3e-f96b-1a1eaa2a2cf8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            "tf.Tensor(\n",
            "[[0.17860734 0.9222386  0.49763513 0.27867055 0.7857331  0.8931309 ]\n",
            " [0.7142072  0.908712   0.19561684 0.5880488  0.99018705 0.02816105]\n",
            " [0.96548665 0.7820189  0.5720879  0.572971   0.7852955  0.880085  ]\n",
            " [0.30672884 0.8750787  0.40881324 0.73967266 0.5764996  0.33520496]], shape=(4, 6), dtype=float32)\n",
            "\n",
            "Rank: 2\n",
            "Shape: [4 6]\n",
            "\n",
            "Reshaped tensor (2, 3, 4):\n",
            "tf.Tensor(\n",
            "[[[0.17860734 0.9222386  0.49763513 0.27867055]\n",
            "  [0.7857331  0.8931309  0.7142072  0.908712  ]\n",
            "  [0.19561684 0.5880488  0.99018705 0.02816105]]\n",
            "\n",
            " [[0.96548665 0.7820189  0.5720879  0.572971  ]\n",
            "  [0.7852955  0.880085   0.30672884 0.8750787 ]\n",
            "  [0.40881324 0.73967266 0.5764996  0.33520496]]], shape=(2, 3, 4), dtype=float32)\n",
            "\n",
            "Transposed tensor (3, 2, 4):\n",
            "tf.Tensor(\n",
            "[[[0.17860734 0.9222386  0.49763513 0.27867055]\n",
            "  [0.96548665 0.7820189  0.5720879  0.572971  ]]\n",
            "\n",
            " [[0.7857331  0.8931309  0.7142072  0.908712  ]\n",
            "  [0.7852955  0.880085   0.30672884 0.8750787 ]]\n",
            "\n",
            " [[0.19561684 0.5880488  0.99018705 0.02816105]\n",
            "  [0.40881324 0.73967266 0.5764996  0.33520496]]], shape=(3, 2, 4), dtype=float32)\n",
            "\n",
            "Rank after reshaping: 3\n",
            "Shape after reshaping: [2 3 4]\n",
            "Rank after transposing: 3\n",
            "Shape after transposing: [3 2 4]\n",
            "\n",
            "Smaller tensor (1, 4):\n",
            "tf.Tensor([[0.8176372  0.16717386 0.75134706 0.7561159 ]], shape=(1, 4), dtype=float32)\n",
            "\n",
            "Result after broadcasting and addition:\n",
            "tf.Tensor(\n",
            "[[[0.99624455 1.0894125  1.2489822  1.0347865 ]\n",
            "  [1.6033703  1.0603048  1.4655542  1.664828  ]\n",
            "  [1.013254   0.7552227  1.7415341  0.78427696]]\n",
            "\n",
            " [[1.7831239  0.94919276 1.323435   1.3290869 ]\n",
            "  [1.6029327  1.0472589  1.0580759  1.6311946 ]\n",
            "  [1.2264504  0.9068465  1.3278466  1.0913209 ]]], shape=(2, 3, 4), dtype=float32)\n",
            "\n",
            "Explanation of broadcasting:\n",
            "Broadcasting in TensorFlow allows arithmetic operations between tensors of different shapes.\n",
            "The smaller tensor (1, 4) is broadcast to match the shape of the reshaped tensor (2, 3, 4).\n",
            "1. The smaller tensor is expanded to (1, 1, 4).\n",
            "2. This is then repeated to match the shape (2, 3, 4).\n",
            "3. Finally, element-wise addition is performed.\n",
            "This allows efficient operations between tensors of different shapes without manually replicating data.\n"
          ]
        }
      ]
    }
  ]
}